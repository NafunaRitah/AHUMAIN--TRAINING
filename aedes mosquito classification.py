# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WWMWnKA8Fcg2sfi-4B-f9JwZj1pz6ADF
"""

! unzip /content/drive/MyDrive/proect-work/mosquito.zip -d /content/drive/MyDrive/proect-work #unzipping data

!pip install ultralytics



import os

os.listdir('/content/aegypti')

import keras
image_size = (180, 180)
batch_size = 128

train_ds, val_ds = keras.utils.image_dataset_from_directory(
    "/content/drive/MyDrive/proect-work/aegypti/aegypti",
    validation_split=0.2,
    subset="both",
    seed=1337,
    image_size=image_size,
    batch_size=batch_size,
)

#  image_size = (180, 180)
# batch_size = 128

# train_ds, val_ds = keras.utils.image_dataset_from_directory(
#     "/content/drive/MyDrive/proect-work/albopictus/albopictus",
#     validation_split=0.2,
#     subset="both",
#     seed=1337,
#     image_size=image_size,
#     batch_size=batch_size,
# )

!pip install ultralytics

from keras.layers import Input, Lambda, Dense, Flatten
from keras.models import Model
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator

from keras.models import Sequential
import numpy as np
from glob import glob
import matplotlib.pyplot as plt
#from keras.layers.core import Flatten, Dense, Dropout
#from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D
#from keras.optimizers import SGD
#import cv2,


import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

IMAGE_SIZE =[224,224]

from PIL import Image
import os
from IPython.display import display
from IPython.display import Image as _Imgdis

#create a object

#def VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, classifier_activation='softmax')


vgg = VGG16(input_shape= IMAGE_SIZE + [3], weights='imagenet', include_top=False)

for layer in vgg.layers:
  layer.trainable = False

train_path = '/content/drive/MyDrive/project-work/train'
test_path = '/content/drive/MyDrive/project-work/test'

# library glob used when you want to see how many folders are in the particular directory
import os
folders =os.listdir(train_path)

#glob(train_path)
print(len(folders))

folders =os.listdir(test_path)

print(len(folders))

x = Flatten()(vgg.output)  # Flatten means taking into account outputs coming from the previous layer and constructing
prediction = Dense(len(folders),activation='softmax')(x)   #dense you specify the number of classes( the folders)
model = Model(inputs=vgg.input, outputs=prediction)
model.summary() # gives a picture of your entire model

from keras import optimizers
adm =optimizers.Adam()
model.compile(
  loss='binary_crossentropy',
  optimizer=adm,
  metrics=['accuracy']
)

train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

test_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

train_set = train_datagen.flow_from_directory( train_path,

    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical')

test_set = test_datagen.flow_from_directory(
   test_path,
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical')

# train model
from datetime import datetime
from keras.callbacks import ModelCheckpoint
checkpoint = ModelCheckpoint(filepath = 'mymodel.h5',  verbose=2,
                             save_best_only=True,)
callbacks = [checkpoint]

start = datetime.now()   # fn to keep how much time the training process took.

model_history = model.fit_generator(
    train_set,
    validation_data=test_set,
    epochs=20,
    steps_per_epoch=5,
    validation_steps=32,
    callbacks=callbacks, verbose=2)

duration = datetime.now()-start
print('Training compeleted in time:', duration)

plt.figure(figsize = (16, 8))

# Plotting the Training and Validation Loss
plt.plot(model_history.history['loss'],label='train loss')
plt.plot(model_history.history['val_loss'],label=' loss')
plt.legend()
plt.xlabel("Epochs")
plt.ylabel("Loss")

# Plotting the Training and Validation Accuracy
plt.figure(figsize = (16, 8))
plt.plot(model_history.history['accuracy'],label='train accuracy')
plt.plot(model_history.history['val_accuracy'],label='val accuracy')
plt.legend()
plt.xlabel("Epochs")
plt.ylabel("Accuracy")